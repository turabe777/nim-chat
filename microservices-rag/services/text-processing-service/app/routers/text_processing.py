"""
Text Processing API

ãƒ†ã‚­ã‚¹ãƒˆåˆ†å‰²ãƒ»ãƒãƒ£ãƒ³ã‚¯ç®¡ç†ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
"""

from fastapi import APIRouter, HTTPException, Depends, Path, Query
from typing import List, Optional
from uuid import UUID
import time

from shared.models.text_processing import (
    TextProcessingRequest, TextProcessingResponse, TextProcessingConfig,
    ChunkListResponse, ChunkDetailResponse, TextStatsResponse
)
from shared.utils.config import TextProcessingServiceConfig
from shared.utils.logging import get_logger
from shared.utils.exceptions import DocumentNotFoundError, ProcessingError
from ..services.text_splitter import TextSplitterService
from ..services.chunk_manager import ChunkManagerService

router = APIRouter(prefix="/text")
logger = get_logger(__name__)
config = TextProcessingServiceConfig()


def get_text_splitter() -> TextSplitterService:
    """ãƒ†ã‚­ã‚¹ãƒˆåˆ†å‰²ã‚µãƒ¼ãƒ“ã‚¹ã®ä¾å­˜é–¢ä¿‚æ³¨å…¥"""
    return TextSplitterService()


def get_chunk_manager() -> ChunkManagerService:
    """ãƒãƒ£ãƒ³ã‚¯ç®¡ç†ã‚µãƒ¼ãƒ“ã‚¹ã®ä¾å­˜é–¢ä¿‚æ³¨å…¥"""
    return ChunkManagerService(config.storage_path)


@router.post("/process", response_model=TextProcessingResponse)
async def process_text(
    request: TextProcessingRequest,
    text_splitter: TextSplitterService = Depends(get_text_splitter),
    chunk_manager: ChunkManagerService = Depends(get_chunk_manager)
):
    """ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†å‰²ã—ã¦ãƒãƒ£ãƒ³ã‚¯ã‚’ä½œæˆ"""
    
    logger.info(f"ğŸ“„ Processing text for document {request.document_id}")
    
    start_time = time.time()
    
    try:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã¾ãŸã¯ãƒªã‚¯ã‚¨ã‚¹ãƒˆè¨­å®šã‚’ä½¿ç”¨
        processing_config = request.config or TextProcessingConfig(
            chunk_size=config.default_chunk_size,
            chunk_overlap=config.default_chunk_overlap
        )
        
        # ãƒ†ã‚­ã‚¹ãƒˆåˆ†å‰²
        chunks = await text_splitter.split_text(
            document_id=request.document_id,
            text=request.text,
            config=processing_config
        )
        
        # ãƒãƒ£ãƒ³ã‚¯ä¿å­˜
        await chunk_manager.save_chunks(request.document_id, chunks)
        
        processing_time = time.time() - start_time
        
        logger.info(f"âœ… Processed {len(chunks)} chunks for document {request.document_id}")
        
        return TextProcessingResponse(
            service=config.service_name,
            document_id=request.document_id,
            chunks=chunks,
            total_chunks=len(chunks),
            original_length=len(request.text),
            processed_length=sum(len(chunk.content) for chunk in chunks),
            processing_time=processing_time,
            config_used=processing_config
        )
        
    except Exception as e:
        logger.error(f"âŒ Failed to process text for {request.document_id}: {str(e)}")
        raise ProcessingError("text_processing", str(e))


@router.get("/chunks/{document_id}", response_model=ChunkListResponse)
async def get_chunks(
    document_id: UUID = Path(..., description="ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆID"),
    limit: Optional[int] = Query(100, le=1000, description="å–å¾—æ•°ä¸Šé™"),
    offset: int = Query(0, ge=0, description="ã‚ªãƒ•ã‚»ãƒƒãƒˆ"),
    chunk_manager: ChunkManagerService = Depends(get_chunk_manager)
):
    """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ãƒãƒ£ãƒ³ã‚¯ä¸€è¦§ã‚’å–å¾—"""
    
    logger.info(f"ğŸ“– Getting chunks for document {document_id}")
    
    try:
        chunks = await chunk_manager.get_chunks(document_id, limit, offset)
        
        # ç·æ•°å–å¾—ï¼ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ï¼‰
        metadata = await chunk_manager.get_chunk_metadata(document_id)
        total_chunks = metadata.get('total_chunks', len(chunks)) if metadata else len(chunks)
        
        return ChunkListResponse(
            service=config.service_name,
            document_id=document_id,
            chunks=chunks,
            total_chunks=total_chunks,
            limit=limit or len(chunks),
            offset=offset
        )
        
    except DocumentNotFoundError:
        raise HTTPException(
            status_code=404,
            detail=f"Chunks not found for document {document_id}"
        )
    except Exception as e:
        logger.error(f"âŒ Failed to get chunks for {document_id}: {str(e)}")
        raise ProcessingError("chunk_retrieval", str(e))


@router.get("/chunks/{document_id}/{chunk_id}", response_model=ChunkDetailResponse)
async def get_chunk_detail(
    document_id: UUID = Path(..., description="ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆID"),
    chunk_id: UUID = Path(..., description="ãƒãƒ£ãƒ³ã‚¯ID"),
    chunk_manager: ChunkManagerService = Depends(get_chunk_manager)
):
    """æŒ‡å®šã•ã‚ŒãŸãƒãƒ£ãƒ³ã‚¯ã®è©³ç´°ã‚’å–å¾—"""
    
    logger.info(f"ğŸ“ Getting chunk detail {chunk_id} for document {document_id}")
    
    try:
        chunk = await chunk_manager.get_chunk_by_id(document_id, chunk_id)
        
        if not chunk:
            raise HTTPException(
                status_code=404,
                detail=f"Chunk {chunk_id} not found in document {document_id}"
            )
        
        return ChunkDetailResponse(
            service=config.service_name,
            chunk=chunk
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ Failed to get chunk {chunk_id}: {str(e)}")
        raise ProcessingError("chunk_detail", str(e))


@router.get("/stats/{document_id}", response_model=TextStatsResponse)
async def get_text_statistics(
    document_id: UUID = Path(..., description="ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆID"),
    chunk_manager: ChunkManagerService = Depends(get_chunk_manager)
):
    """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ãƒ†ã‚­ã‚¹ãƒˆçµ±è¨ˆã‚’å–å¾—"""
    
    logger.info(f"ğŸ“Š Getting text statistics for document {document_id}")
    
    try:
        stats = await chunk_manager.get_statistics(document_id)
        
        if not stats:
            raise HTTPException(
                status_code=404,
                detail=f"Statistics not found for document {document_id}"
            )
        
        return TextStatsResponse(
            service=config.service_name,
            document_id=document_id,
            total_chunks=stats['total_chunks'],
            total_characters=stats['total_characters'],
            average_chunk_size=stats['average_chunk_size'],
            min_chunk_size=stats['min_chunk_size'],
            max_chunk_size=stats['max_chunk_size'],
            processing_date=stats['created_at']
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ Failed to get statistics for {document_id}: {str(e)}")
        raise ProcessingError("statistics", str(e))


@router.delete("/chunks/{document_id}")
async def delete_chunks(
    document_id: UUID = Path(..., description="ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆID"),
    chunk_manager: ChunkManagerService = Depends(get_chunk_manager)
):
    """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ãƒãƒ£ãƒ³ã‚¯ã‚’å‰Šé™¤"""
    
    logger.info(f"ğŸ—‘ï¸ Deleting chunks for document {document_id}")
    
    try:
        success = await chunk_manager.delete_chunks(document_id)
        
        if not success:
            raise HTTPException(
                status_code=404,
                detail=f"Chunks not found for document {document_id}"
            )
        
        logger.info(f"âœ… Deleted chunks for document {document_id}")
        return {"message": "Chunks deleted successfully"}
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ Failed to delete chunks for {document_id}: {str(e)}")
        raise ProcessingError("chunk_deletion", str(e))


@router.get("/documents")
async def list_processed_documents(
    chunk_manager: ChunkManagerService = Depends(get_chunk_manager)
):
    """å‡¦ç†æ¸ˆã¿ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä¸€è¦§ã‚’å–å¾—"""
    
    logger.info("ğŸ“‹ Listing processed documents")
    
    try:
        documents = await chunk_manager.list_processed_documents()
        
        logger.info(f"ğŸ“Š Found {len(documents)} processed documents")
        
        return {
            "service": config.service_name,
            "success": True,
            "documents": documents,
            "total_count": len(documents)
        }
        
    except Exception as e:
        logger.error(f"âŒ Failed to list processed documents: {str(e)}")
        raise ProcessingError("document_listing", str(e))