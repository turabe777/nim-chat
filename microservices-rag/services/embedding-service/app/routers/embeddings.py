"""
Embedding API

åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆãƒ»ç®¡ç†ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
"""

from fastapi import APIRouter, HTTPException, Depends, Path, Query
from typing import List, Optional
from uuid import UUID
import time

from shared.models.embedding import (
    EmbeddingRequest, EmbeddingResponse, EmbeddingConfig,
    BatchEmbeddingRequest, EmbeddingListResponse, EmbeddingDetailResponse,
    EmbeddingStatsResponse, SimilaritySearchRequest, SimilaritySearchResponse,
    ModelInfoResponse, SimilarityResult
)
from shared.utils.config import EmbeddingServiceConfig
from shared.utils.logging import get_logger
from shared.utils.exceptions import DocumentNotFoundError, ProcessingError
from ..services.embedding_generator import EmbeddingGeneratorService
from ..services.embedding_manager import EmbeddingManagerService

router = APIRouter(prefix="/embeddings")
logger = get_logger(__name__)
config = EmbeddingServiceConfig()


def get_embedding_generator() -> EmbeddingGeneratorService:
    """åŸ‹ã‚è¾¼ã¿ç”Ÿæˆã‚µãƒ¼ãƒ“ã‚¹ã®ä¾å­˜é–¢ä¿‚æ³¨å…¥"""
    return EmbeddingGeneratorService()


def get_embedding_manager() -> EmbeddingManagerService:
    """åŸ‹ã‚è¾¼ã¿ç®¡ç†ã‚µãƒ¼ãƒ“ã‚¹ã®ä¾å­˜é–¢ä¿‚æ³¨å…¥"""
    return EmbeddingManagerService(config.storage_path)


@router.post("/generate", response_model=EmbeddingResponse)
async def generate_embeddings(
    request: EmbeddingRequest,
    generator: EmbeddingGeneratorService = Depends(get_embedding_generator),
    manager: EmbeddingManagerService = Depends(get_embedding_manager)
):
    """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆ"""
    
    logger.info(f"ğŸ”® Generating embeddings for {len(request.texts)} texts")
    
    start_time = time.time()
    
    try:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã¾ãŸã¯ãƒªã‚¯ã‚¨ã‚¹ãƒˆè¨­å®šã‚’ä½¿ç”¨
        embedding_config = request.config or EmbeddingConfig(
            model_name=config.default_embedding_model,
            batch_size=min(config.max_batch_size, len(request.texts))
        )
        
        # åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ
        embeddings = await generator.generate_embeddings(
            texts=request.texts,
            chunk_ids=request.chunk_ids,
            document_id=request.document_id,
            config=embedding_config
        )
        
        # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆIDãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚Œã°ä¿å­˜
        if request.document_id:
            await manager.save_embeddings(request.document_id, embeddings)
        
        processing_time = time.time() - start_time
        model_info = generator.get_model_info()
        
        logger.info(f"âœ… Generated {len(embeddings)} embeddings in {processing_time:.3f}s")
        
        return EmbeddingResponse(
            service=config.service_name,
            embeddings=embeddings,
            total_count=len(embeddings),
            model_info=model_info,
            processing_time=processing_time,
            config_used=embedding_config
        )
        
    except Exception as e:
        logger.error(f"âŒ Failed to generate embeddings: {str(e)}")
        raise ProcessingError("embedding_generation", str(e))


@router.post("/batch", response_model=EmbeddingResponse)
async def generate_batch_embeddings(
    request: BatchEmbeddingRequest,
    generator: EmbeddingGeneratorService = Depends(get_embedding_generator),
    manager: EmbeddingManagerService = Depends(get_embedding_manager)
):
    """ãƒãƒ£ãƒ³ã‚¯ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ä¸€æ‹¬ã§åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆ"""
    
    logger.info(f"ğŸ“¦ Batch generating embeddings for {len(request.chunks)} chunks")
    
    start_time = time.time()
    
    try:
        # ãƒãƒ£ãƒ³ã‚¯ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ texts ã¨ chunk_ids ã‚’æŠ½å‡º
        texts = [chunk['content'] for chunk in request.chunks]
        chunk_ids = [UUID(chunk['chunk_id']) for chunk in request.chunks]
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
        embedding_config = request.config or EmbeddingConfig(
            model_name=config.default_embedding_model,
            batch_size=min(config.max_batch_size, len(texts))
        )
        
        # åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ
        embeddings = await generator.generate_embeddings(
            texts=texts,
            chunk_ids=chunk_ids,
            document_id=request.document_id,
            config=embedding_config
        )
        
        # åŸ‹ã‚è¾¼ã¿ä¿å­˜
        await manager.save_embeddings(request.document_id, embeddings)
        
        processing_time = time.time() - start_time
        model_info = generator.get_model_info()
        
        logger.info(f"âœ… Batch generated {len(embeddings)} embeddings in {processing_time:.3f}s")
        
        return EmbeddingResponse(
            service=config.service_name,
            embeddings=embeddings,
            total_count=len(embeddings),
            model_info=model_info,
            processing_time=processing_time,
            config_used=embedding_config
        )
        
    except Exception as e:
        logger.error(f"âŒ Failed to generate batch embeddings: {str(e)}")
        raise ProcessingError("batch_embedding_generation", str(e))


@router.get("/documents/{document_id}", response_model=EmbeddingListResponse)
async def get_embeddings(
    document_id: UUID = Path(..., description="ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆID"),
    limit: Optional[int] = Query(100, le=1000, description="å–å¾—æ•°ä¸Šé™"),
    offset: int = Query(0, ge=0, description="ã‚ªãƒ•ã‚»ãƒƒãƒˆ"),
    manager: EmbeddingManagerService = Depends(get_embedding_manager)
):
    """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ä¸€è¦§ã‚’å–å¾—"""
    
    logger.info(f"ğŸ“– Getting embeddings for document {document_id}")
    
    try:
        embeddings = await manager.get_embeddings(document_id, limit, offset)
        
        # ç·æ•°å–å¾—ï¼ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ï¼‰
        metadata = await manager.get_embedding_metadata(document_id)
        total_count = metadata.get('total_embeddings', len(embeddings)) if metadata else len(embeddings)
        
        return EmbeddingListResponse(
            service=config.service_name,
            embeddings=embeddings,
            total_count=total_count,
            limit=limit or len(embeddings),
            offset=offset,
            filter_applied={"document_id": str(document_id)}
        )
        
    except DocumentNotFoundError:
        raise HTTPException(
            status_code=404,
            detail=f"Embeddings not found for document {document_id}"
        )
    except Exception as e:
        logger.error(f"âŒ Failed to get embeddings for {document_id}: {str(e)}")
        raise ProcessingError("embedding_retrieval", str(e))


@router.get("/documents/{document_id}/{embedding_id}", response_model=EmbeddingDetailResponse)
async def get_embedding_detail(
    document_id: UUID = Path(..., description="ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆID"),
    embedding_id: UUID = Path(..., description="åŸ‹ã‚è¾¼ã¿ID"),
    manager: EmbeddingManagerService = Depends(get_embedding_manager)
):
    """æŒ‡å®šã•ã‚ŒãŸåŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã®è©³ç´°ã‚’å–å¾—"""
    
    logger.info(f"ğŸ“ Getting embedding detail {embedding_id} for document {document_id}")
    
    try:
        embedding = await manager.get_embedding_by_id(document_id, embedding_id)
        
        if not embedding:
            raise HTTPException(
                status_code=404,
                detail=f"Embedding {embedding_id} not found in document {document_id}"
            )
        
        return EmbeddingDetailResponse(
            service=config.service_name,
            embedding=embedding
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ Failed to get embedding {embedding_id}: {str(e)}")
        raise ProcessingError("embedding_detail", str(e))


@router.get("/stats/{document_id}", response_model=EmbeddingStatsResponse)
async def get_embedding_statistics(
    document_id: UUID = Path(..., description="ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆID"),
    manager: EmbeddingManagerService = Depends(get_embedding_manager)
):
    """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®åŸ‹ã‚è¾¼ã¿çµ±è¨ˆã‚’å–å¾—"""
    
    logger.info(f"ğŸ“Š Getting embedding statistics for document {document_id}")
    
    try:
        stats = await manager.get_statistics(document_id)
        
        if not stats:
            raise HTTPException(
                status_code=404,
                detail=f"Statistics not found for document {document_id}"
            )
        
        return EmbeddingStatsResponse(
            service=config.service_name,
            document_id=document_id,
            total_embeddings=stats['total_embeddings'],
            dimension=stats['dimension'],
            model_name=stats['model_name'],
            average_vector_norm=stats['average_vector_norm'],
            created_date_range={
                "start": stats['created_at'],
                "end": stats['created_at']  # å˜ä¸€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãªã®ã§åŒã˜
            },
            storage_size_mb=stats['storage_size_mb']
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ Failed to get statistics for {document_id}: {str(e)}")
        raise ProcessingError("statistics", str(e))


@router.post("/search", response_model=SimilaritySearchResponse)
async def search_similar_embeddings(
    request: SimilaritySearchRequest,
    generator: EmbeddingGeneratorService = Depends(get_embedding_generator),
    manager: EmbeddingManagerService = Depends(get_embedding_manager)
):
    """é¡ä¼¼åº¦æ¤œç´¢"""
    
    logger.info(f"ğŸ” Searching similar embeddings, top_k={request.top_k}")
    
    start_time = time.time()
    
    try:
        results = []
        total_candidates = 0
        
        # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯çµã‚Šè¾¼ã¿æ¤œç´¢
        document_ids = request.document_ids or []
        
        if not document_ids:
            # ã™ã¹ã¦ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‹ã‚‰æ¤œç´¢
            processed_docs = await manager.list_processed_documents()
            document_ids = [UUID(doc['document_id']) for doc in processed_docs]
        
        # å„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã§é¡ä¼¼åº¦æ¤œç´¢
        for doc_id in document_ids:
            try:
                # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’å–å¾—
                embeddings = await manager.get_embeddings(doc_id)
                if not embeddings:
                    continue
                
                total_candidates += len(embeddings)
                
                # ãƒ™ã‚¯ãƒˆãƒ«ãƒªã‚¹ãƒˆã‚’æº–å‚™
                candidate_vectors = [emb.vector for emb in embeddings]
                
                # é¡ä¼¼åº¦è¨ˆç®—
                similarities = await generator.compute_similarity(
                    query_vector=request.query_vector,
                    candidate_vectors=candidate_vectors,
                    top_k=len(embeddings)  # å…¨å€™è£œã§è¨ˆç®—
                )
                
                # çµæœã«è¿½åŠ 
                for idx, score in similarities:
                    if request.similarity_threshold is None or score >= request.similarity_threshold:
                        embedding = embeddings[idx]
                        result = SimilarityResult(
                            embedding_id=embedding.embedding_id,
                            chunk_id=embedding.chunk_id,
                            document_id=doc_id,
                            similarity_score=score,
                            metadata=embedding.metadata
                        )
                        results.append(result)
                
            except Exception as e:
                logger.warning(f"âš ï¸ Failed to search in document {doc_id}: {str(e)}")
                continue
        
        # çµæœã‚’ã‚¹ã‚³ã‚¢é †ã§ã‚½ãƒ¼ãƒˆã€top_kã«çµã‚Šè¾¼ã¿
        results.sort(key=lambda x: x.similarity_score, reverse=True)
        results = results[:request.top_k]
        
        search_time = time.time() - start_time
        
        logger.info(f"âœ… Found {len(results)} similar embeddings in {search_time:.3f}s")
        
        return SimilaritySearchResponse(
            service=config.service_name,
            results=results,
            query_dimension=len(request.query_vector),
            search_time=search_time,
            total_candidates=total_candidates
        )
        
    except Exception as e:
        logger.error(f"âŒ Failed to search similar embeddings: {str(e)}")
        raise ProcessingError("similarity_search", str(e))


@router.delete("/documents/{document_id}")
async def delete_embeddings(
    document_id: UUID = Path(..., description="ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆID"),
    manager: EmbeddingManagerService = Depends(get_embedding_manager)
):
    """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’å‰Šé™¤"""
    
    logger.info(f"ğŸ—‘ï¸ Deleting embeddings for document {document_id}")
    
    try:
        success = await manager.delete_embeddings(document_id)
        
        if not success:
            raise HTTPException(
                status_code=404,
                detail=f"Embeddings not found for document {document_id}"
            )
        
        logger.info(f"âœ… Deleted embeddings for document {document_id}")
        return {"message": "Embeddings deleted successfully"}
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ Failed to delete embeddings for {document_id}: {str(e)}")
        raise ProcessingError("embedding_deletion", str(e))


@router.get("/models", response_model=ModelInfoResponse)
async def get_model_info(
    generator: EmbeddingGeneratorService = Depends(get_embedding_generator)
):
    """ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’å–å¾—"""
    
    logger.info("ğŸ¤– Getting model information")
    
    try:
        available_models = generator.get_available_models()
        current_model = generator.get_model_info()
        
        device_info = current_model.get('device_info', {})
        
        return ModelInfoResponse(
            service=config.service_name,
            available_models=available_models,
            current_model=current_model,
            device_info=device_info
        )
        
    except Exception as e:
        logger.error(f"âŒ Failed to get model info: {str(e)}")
        raise ProcessingError("model_info", str(e))


@router.get("/documents")
async def list_processed_documents(
    manager: EmbeddingManagerService = Depends(get_embedding_manager)
):
    """å‡¦ç†æ¸ˆã¿ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä¸€è¦§ã‚’å–å¾—"""
    
    logger.info("ğŸ“‹ Listing processed documents")
    
    try:
        documents = await manager.list_processed_documents()
        
        logger.info(f"ğŸ“Š Found {len(documents)} processed documents")
        
        return {
            "service": config.service_name,
            "success": True,
            "documents": documents,
            "total_count": len(documents)
        }
        
    except Exception as e:
        logger.error(f"âŒ Failed to list processed documents: {str(e)}")
        raise ProcessingError("document_listing", str(e))